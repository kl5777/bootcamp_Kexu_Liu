{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 05 — Data Storage\n",
    "Date: Aug 15 (Fri) (B)\n",
    "\n",
    "**Focus:** reproducible save/load; env-driven paths; CSV vs Parquet; raw vs processed.\n",
    "\n",
    "_Brief cloud note_: S3/data lakes support large-scale storage and efficient querying (partitioning, column pruning). No deep dive today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "RAW_DIR = pathlib.Path(os.getenv(\"DATA_DIR_RAW\", \"data/raw\"))\n",
    "PROC_DIR = pathlib.Path(os.getenv(\"DATA_DIR_PROCESSED\", \"data/processed\"))\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"RAW_DIR:\", RAW_DIR.resolve())\n",
    "print(\"PROC_DIR:\", PROC_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sample DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dates = pd.date_range(\"2024-01-01\", periods=10, freq=\"D\")\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'ticker': ['AAPL']*10,\n",
    "    'price': 150 + np.random.randn(10).cumsum()\n",
    "})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV (raw) and Parquet (processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "csv_path = RAW_DIR / f\"prices_{ts()}.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV →\", csv_path)\n",
    "\n",
    "parq_path = PROC_DIR / f\"prices_{ts()}.parquet\"\n",
    "try:\n",
    "    df.to_parquet(parq_path)  # uses installed engine if available\n",
    "    print(\"Saved Parquet →\", parq_path)\n",
    "except Exception as e:\n",
    "    print(\"Parquet save failed (engine missing?). Skipping Parquet demo.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_loaded(original: pd.DataFrame, reloaded: pd.DataFrame, cols=('date','ticker','price')):\n",
    "    checks = {\n",
    "        'shape_equal': original.shape == reloaded.shape,\n",
    "        'cols_present': all(c in reloaded.columns for c in cols)\n",
    "    }\n",
    "    # dtype sanity checks\n",
    "    if 'price' in reloaded.columns:\n",
    "        checks['price_is_numeric'] = pd.api.types.is_numeric_dtype(reloaded['price'])\n",
    "    if 'date' in reloaded.columns:\n",
    "        checks['date_is_datetime'] = pd.api.types.is_datetime64_any_dtype(reloaded['date'])\n",
    "    return checks\n",
    "\n",
    "df_csv = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "print('CSV validation:', validate_loaded(df, df_csv))\n",
    "\n",
    "if parq_path.exists():\n",
    "    try:\n",
    "        df_parq = pd.read_parquet(parq_path)\n",
    "        print('Parquet validation:', validate_loaded(df, df_parq))\n",
    "    except Exception as e:\n",
    "        print('Parquet read failed:', e)\n",
    "else:\n",
    "    print('Parquet file not present (skipped earlier).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO Utilities (suffix-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def ensure_dir(path: pathlib.Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def detect_format(path: Union[str, pathlib.Path]):\n",
    "    suf = str(path).lower()\n",
    "    if suf.endswith('.csv'): return 'csv'\n",
    "    if suf.endswith('.parquet') or suf.endswith('.pq') or suf.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format for: ' + str(path))\n",
    "\n",
    "def write_df(df: pd.DataFrame, path: Union[str, pathlib.Path]):\n",
    "    path = pathlib.Path(path)\n",
    "    ensure_dir(path)\n",
    "    fmt = detect_format(path)\n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(path, index=False)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            df.to_parquet(path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    return path\n",
    "\n",
    "def read_df(path: Union[str, pathlib.Path]):\n",
    "    path = pathlib.Path(path)\n",
    "    fmt = detect_format(path)\n",
    "    if fmt == 'csv':\n",
    "        return pd.read_csv(path, parse_dates=['date']) if 'date' in pd.read_csv(path, nrows=0).columns else pd.read_csv(path)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            return pd.read_parquet(path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "\n",
    "# Demo utility usage\n",
    "csv2 = RAW_DIR / f\"prices_util_{ts()}.csv\"\n",
    "pq2  = PROC_DIR / f\"prices_util_{ts()}.parquet\"\n",
    "write_df(df, csv2)\n",
    "df2 = read_df(csv2)\n",
    "print('Reloaded CSV via util, shape:', df2.shape)\n",
    "\n",
    "try:\n",
    "    write_df(df, pq2)\n",
    "    df3 = read_df(pq2)\n",
    "    print('Reloaded Parquet via util, shape:', df3.shape)\n",
    "except RuntimeError as e:\n",
    "    print('Parquet util demo skipped:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- Env-driven paths → portable IO.\n",
    "- CSV vs Parquet → tradeoffs.\n",
    "- Utilities abstract away format details.\n",
    "- Next: document storage plan in README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
